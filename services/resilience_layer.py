"""
Smart API Resilience Layer
Provides circuit breaker, caching, and intelligent fallback mechanisms
"""
import time
import json
import logging
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime, timedelta
from functools import wraps
from collections import defaultdict

logger = logging.getLogger(__name__)


class CircuitBreaker:
    """
    Prevents cascading failures by failing fast when APIs are down.
    
    States:
    - CLOSED: Normal operation, requests pass through
    - OPEN: Too many failures, requests fail immediately
    - HALF_OPEN: Testing if service recovered
    """
    
    def __init__(
        self, 
        failure_threshold: int = 5, 
        timeout: int = 60, 
        recovery_timeout: int = 300,
        name: str = "unknown"
    ):
        """
        Initialize circuit breaker
        
        Args:
            failure_threshold: Number of failures before opening circuit
            timeout: Seconds to wait before attempting recovery
            recovery_timeout: Seconds to wait in open state before half-open
            name: Name for logging purposes
        """
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.recovery_timeout = recovery_timeout
        self.last_failure_time = None
        self.state = 'closed'  # closed, open, half_open
        self.name = name
        self.success_count = 0
        self.total_calls = 0
        
    def call(self, func: Callable, *args, **kwargs) -> Any:
        """
        Execute function with circuit breaker protection
        
        Args:
            func: Function to execute
            *args: Positional arguments for function
            **kwargs: Keyword arguments for function
            
        Returns:
            Result from function call
            
        Raises:
            Exception: If circuit is open or function fails
        """
        self.total_calls += 1
        
        # If open, check if recovery time has passed
        if self.state == 'open':
            if self.last_failure_time and \
               datetime.now() - self.last_failure_time > timedelta(seconds=self.recovery_timeout):
                self.state = 'half_open'
                logger.info(f"Circuit breaker [{self.name}] transitioning to HALF-OPEN state")
            else:
                remaining = self.recovery_timeout
                if self.last_failure_time:
                    elapsed = (datetime.now() - self.last_failure_time).total_seconds()
                    remaining = max(0, self.recovery_timeout - elapsed)
                raise Exception(
                    f"Circuit breaker OPEN for {self.name}. "
                    f"Retry in {int(remaining)} seconds"
                )
        
        # Try to execute
        try:
            result = func(*args, **kwargs)
            
            # Success - reset failures
            self.success_count += 1
            if self.state == 'half_open':
                self.state = 'closed'
                self.failure_count = 0
                logger.info(
                    f"Circuit breaker [{self.name}] CLOSED - service recovered. "
                    f"Success rate: {self.get_success_rate():.1%}"
                )
            
            return result
            
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = datetime.now()
            
            # Open circuit if threshold exceeded
            if self.failure_count >= self.failure_threshold:
                self.state = 'open'
                logger.error(
                    f"Circuit breaker [{self.name}] OPEN - threshold exceeded. "
                    f"Failures: {self.failure_count}/{self.failure_threshold}. "
                    f"Error: {str(e)}"
                )
            else:
                logger.warning(
                    f"Circuit breaker [{self.name}] failure {self.failure_count}/"
                    f"{self.failure_threshold}: {str(e)}"
                )
            
            raise
    
    def get_success_rate(self) -> float:
        """Calculate success rate"""
        if self.total_calls == 0:
            return 0.0
        return self.success_count / self.total_calls
    
    def get_state(self) -> Dict[str, Any]:
        """Get current circuit breaker state"""
        return {
            'name': self.name,
            'state': self.state,
            'failure_count': self.failure_count,
            'success_count': self.success_count,
            'total_calls': self.total_calls,
            'success_rate': self.get_success_rate(),
            'last_failure': self.last_failure_time.isoformat() if self.last_failure_time else None
        }
    
    def reset(self):
        """Manually reset circuit breaker"""
        self.state = 'closed'
        self.failure_count = 0
        self.last_failure_time = None
        logger.info(f"Circuit breaker [{self.name}] manually RESET")


class CacheLayer:
    """
    Intelligent caching with TTL and smart invalidation
    
    In production, replace with Redis for distributed caching
    """
    
    def __init__(self, ttl_seconds: int = 3600, name: str = "cache"):
        """
        Initialize cache layer
        
        Args:
            ttl_seconds: Time-to-live in seconds
            name: Name for logging purposes
        """
        self.cache = {}  # In production, use Redis
        self.ttl_seconds = ttl_seconds
        self.name = name
        self.stats = {
            'hits': 0,
            'misses': 0,
            'sets': 0,
            'invalidations': 0
        }
        
    def get(self, key: str) -> Optional[Any]:
        """
        Get from cache if not expired
        
        Args:
            key: Cache key
            
        Returns:
            Cached value or None if not found/expired
        """
        if key not in self.cache:
            self.stats['misses'] += 1
            logger.debug(f"Cache [{self.name}] MISS: {key}")
            return None
            
        data, timestamp = self.cache[key]
        
        # Check if expired
        age_seconds = (datetime.now() - timestamp).total_seconds()
        if age_seconds > self.ttl_seconds:
            del self.cache[key]
            self.stats['misses'] += 1
            logger.debug(f"Cache [{self.name}] EXPIRED: {key} (age: {age_seconds:.0f}s)")
            return None
        
        self.stats['hits'] += 1
        logger.debug(f"Cache [{self.name}] HIT: {key} (age: {age_seconds:.0f}s)")
        return data
    
    def set(self, key: str, value: Any) -> None:
        """
        Store in cache
        
        Args:
            key: Cache key
            value: Value to cache
        """
        self.cache[key] = (value, datetime.now())
        self.stats['sets'] += 1
        logger.debug(f"Cache [{self.name}] SET: {key}")
    
    def invalidate(self, key: str) -> bool:
        """
        Invalidate specific cache entry
        
        Args:
            key: Cache key to invalidate
            
        Returns:
            True if key existed, False otherwise
        """
        if key in self.cache:
            del self.cache[key]
            self.stats['invalidations'] += 1
            logger.debug(f"Cache [{self.name}] INVALIDATE: {key}")
            return True
        return False
    
    def invalidate_pattern(self, pattern: str) -> int:
        """
        Invalidate cache entries matching pattern
        
        Args:
            pattern: String pattern to match (simple substring match)
            
        Returns:
            Number of entries invalidated
        """
        keys_to_delete = [k for k in self.cache.keys() if pattern in k]
        for key in keys_to_delete:
            del self.cache[key]
        
        count = len(keys_to_delete)
        self.stats['invalidations'] += count
        logger.info(f"Cache [{self.name}] invalidated {count} entries matching '{pattern}'")
        return count
    
    def clear(self) -> int:
        """
        Clear all cache entries
        
        Returns:
            Number of entries cleared
        """
        count = len(self.cache)
        self.cache.clear()
        self.stats['invalidations'] += count
        logger.info(f"Cache [{self.name}] cleared {count} entries")
        return count
    
    def get_stats(self) -> Dict[str, Any]:
        """Get cache statistics"""
        total_requests = self.stats['hits'] + self.stats['misses']
        hit_rate = self.stats['hits'] / total_requests if total_requests > 0 else 0
        
        return {
            'name': self.name,
            'ttl_seconds': self.ttl_seconds,
            'size': len(self.cache),
            'hits': self.stats['hits'],
            'misses': self.stats['misses'],
            'hit_rate': hit_rate,
            'sets': self.stats['sets'],
            'invalidations': self.stats['invalidations']
        }
    
    def get_age(self, key: str) -> Optional[float]:
        """
        Get age of cached entry in seconds
        
        Args:
            key: Cache key
            
        Returns:
            Age in seconds or None if not found
        """
        if key not in self.cache:
            return None
        _, timestamp = self.cache[key]
        return (datetime.now() - timestamp).total_seconds()


class ResilientPropertyService:
    """
    Property service with intelligent fallback chain:
    1. Repliers API (primary)
    2. Warm cache (< 1 hour old)
    3. Historical cache (< 7 days old)
    4. Statistical model (ML-based estimation)
    5. Synthetic data (last resort)
    """
    
    def __init__(self):
        """Initialize resilient property service"""
        # Circuit breakers for different services
        self.repliers_breaker = CircuitBreaker(
            failure_threshold=5, 
            recovery_timeout=300,  # 5 minutes
            name="repliers_api"
        )
        self.exa_breaker = CircuitBreaker(
            failure_threshold=3, 
            recovery_timeout=180,  # 3 minutes
            name="exa_api"
        )
        
        # Cache layers
        self.cache = CacheLayer(ttl_seconds=3600, name="warm_cache")  # 1 hour
        self.historical_cache = CacheLayer(ttl_seconds=604800, name="historical_cache")  # 7 days
        
        # Statistics
        self.fallback_stats = defaultdict(int)
        
    def search_properties(
        self, 
        location: str, 
        min_price: Optional[float] = None,
        max_price: Optional[float] = None,
        bedrooms: Optional[int] = None,
        bathrooms: Optional[float] = None,
        property_type: Optional[str] = None,
        limit: int = 10,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Search properties with intelligent fallback chain
        
        Args:
            location: City or area name
            min_price: Minimum price filter
            max_price: Maximum price filter
            bedrooms: Number of bedrooms
            bathrooms: Number of bathrooms
            property_type: Type of property
            limit: Maximum number of results
            **kwargs: Additional filters
            
        Returns:
            Dictionary with properties and metadata
        """
        # Generate cache key
        filters = {
            'min_price': min_price,
            'max_price': max_price,
            'bedrooms': bedrooms,
            'bathrooms': bathrooms,
            'property_type': property_type,
            'limit': limit
        }
        filters.update(kwargs)
        cache_key = self._generate_cache_key(location, filters)
        
        # Try primary source (Repliers API)
        try:
            logger.info(f"ðŸ” Attempting PRIMARY search for: {location}")
            
            result = self.repliers_breaker.call(
                self._search_repliers,
                location, 
                min_price=min_price,
                max_price=max_price,
                bedrooms=bedrooms,
                bathrooms=bathrooms,
                property_type=property_type,
                limit=limit,
                **kwargs
            )
            
            if result and result.get('properties'):
                # Cache successful result in both layers
                self.cache.set(cache_key, result)
                self.historical_cache.set(cache_key, result)
                self.fallback_stats['primary_success'] += 1
                
                logger.info(
                    f"âœ… PRIMARY source SUCCESS: {len(result['properties'])} properties found"
                )
                return result
                
        except Exception as e:
            logger.warning(f"âš ï¸ Primary source failed: {str(e)}")
            self.fallback_stats['primary_failure'] += 1
        
        # Fallback 1: Check warm cache (recent data)
        cached_result = self.cache.get(cache_key)
        if cached_result:
            age = self.cache.get_age(cache_key)
            logger.info(f"ðŸ“¦ Using WARM CACHE for {location} (age: {age:.0f}s)")
            cached_result['source'] = 'warm_cache'
            cached_result['cache_age_seconds'] = age
            self.fallback_stats['warm_cache'] += 1
            return cached_result
        
        # Fallback 2: Check historical cache (older but reliable)
        historical_result = self.historical_cache.get(cache_key)
        if historical_result:
            age = self.historical_cache.get_age(cache_key)
            logger.info(f"ðŸ“š Using HISTORICAL CACHE for {location} (age: {age:.0f}s)")
            historical_result['source'] = 'historical_cache'
            historical_result['cache_age_seconds'] = age
            
            # Mark properties as potentially stale
            for prop in historical_result.get('properties', []):
                prop['cache_age_hours'] = age / 3600
            
            self.fallback_stats['historical_cache'] += 1
            return historical_result
        
        # Fallback 3: Statistical model
        logger.warning(f"ðŸ¤– Using STATISTICAL MODEL for {location}")
        model_result = self._generate_from_model(location, filters)
        if model_result:
            self.fallback_stats['statistical_model'] += 1
            return model_result
        
        # Fallback 4: Synthetic data (last resort)
        logger.error(f"âš ï¸ All sources exhausted, generating SYNTHETIC data for {location}")
        self.fallback_stats['synthetic_fallback'] += 1
        return self._generate_synthetic_properties(location, filters)
    
    def _search_repliers(
        self, 
        location: str, 
        min_price: Optional[float] = None,
        max_price: Optional[float] = None,
        bedrooms: Optional[int] = None,
        bathrooms: Optional[float] = None,
        property_type: Optional[str] = None,
        limit: int = 10,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Search primary Repliers API with timeout
        
        Args:
            location: City or area name
            min_price: Minimum price filter
            max_price: Maximum price filter
            bedrooms: Number of bedrooms
            bathrooms: Number of bathrooms
            property_type: Type of property
            limit: Maximum number of results
            **kwargs: Additional filters
            
        Returns:
            Search results from Repliers API
        """
        from services.listings_service import listings_service
        
        # Build search parameters
        search_params = {
            'city': location,
            'page_size': limit,
            'status': 'active'
        }
        
        if min_price:
            search_params['min_price'] = min_price
        if max_price:
            search_params['max_price'] = max_price
        if bedrooms:
            search_params['min_bedrooms'] = bedrooms
        if bathrooms:
            search_params['min_bathrooms'] = bathrooms
        if property_type:
            search_params['property_type'] = property_type
        
        # Add any additional kwargs
        search_params.update(kwargs)
        
        # Call listings service
        result = listings_service.search_listings(**search_params)
        
        if not result.get('success'):
            raise Exception(f"Repliers API returned error: {result.get('error', 'Unknown error')}")
        
        return {
            'properties': result.get('listings', []),
            'total_found': result.get('count', 0),
            'source': 'repliers_api',
            'timestamp': datetime.now().isoformat()
        }
    
    def _generate_from_model(self, location: str, filters: Dict) -> Optional[Dict]:
        """
        Generate realistic properties from statistical model
        
        In production, this would use a trained ML model based on historical data
        
        Args:
            location: City or area name
            filters: Search filters
            
        Returns:
            Dictionary with generated properties
        """
        properties = []
        limit = filters.get('limit', 10)
        
        # Use filter values or dynamic defaults based on listing type
        listing_type = filters.get('transaction_type', 'sale')
        if listing_type == 'lease':
            # Rental defaults in CAD per month
            base_price = filters.get('max_price') or 6000  # $6k/month max for rentals
            min_price = filters.get('min_price') or 1500   # $1.5k/month min for rentals
        else:
            # Sale defaults in CAD total price
            base_price = filters.get('max_price') or 800000  # $800k max for sales
            min_price = filters.get('min_price') or 500000  # $500k min for sales
        
        bedrooms = filters.get('bedrooms') or 3
        bathrooms = filters.get('bathrooms') or 2
        
        # Generate representative properties with price range
        for i in range(min(5, limit)):
            price = base_price - (i * 50000)
            
            properties.append({
                'id': f'model_{location.lower().replace(" ", "_")}_{i}',
                'address': f'{100 + i*50} {location} Avenue',
                'city': location,
                'price': price,
                'bedrooms': bedrooms,
                'bathrooms': bathrooms,
                'sqft': 2200 + (i * 100),
                'mls_number': f'MODEL{location[:3].upper()}{i:04d}',
                'property_type': filters.get('property_type', 'residential'),
                'images': [],
                'status': 'active',
                'source_type': 'statistical_model',
                'description': f'Representative {bedrooms}BR property in {location}',
                'listed_date': datetime.now().isoformat()
            })
        
        return {
            'properties': properties,
            'total_found': len(properties),
            'source': 'statistical_model',
            'warning': 'Using statistical model due to API unavailability',
            'timestamp': datetime.now().isoformat()
        }
    
    def _generate_synthetic_properties(self, location: str, filters: Dict) -> Dict:
        """
        Last resort: generate synthetic data
        
        Args:
            location: City or area name
            filters: Search filters
            
        Returns:
            Dictionary with synthetic properties
        """
        # Similar to model but clearly marked as synthetic
        result = self._generate_from_model(location, filters)
        result['source'] = 'synthetic_fallback'
        result['warning'] = 'System currently unavailable. Showing representative data.'
        result['notice'] = 'These are example properties for demonstration purposes only.'
        
        return result
    
    def _generate_cache_key(self, location: str, filters: Dict) -> str:
        """
        Generate consistent cache key from location and filters
        
        Args:
            location: City or area name
            filters: Search filters
            
        Returns:
            Cache key string
        """
        # Sort filters for consistent key generation
        sorted_filters = json.dumps(sorted(filters.items()), default=str)
        return f"{location.lower()}_{sorted_filters}"
    
    def get_health_status(self) -> Dict[str, Any]:
        """
        Get health status of all components
        
        Returns:
            Dictionary with health information
        """
        return {
            'circuit_breakers': {
                'repliers': self.repliers_breaker.get_state(),
                'exa': self.exa_breaker.get_state()
            },
            'caches': {
                'warm': self.cache.get_stats(),
                'historical': self.historical_cache.get_stats()
            },
            'fallback_stats': dict(self.fallback_stats),
            'timestamp': datetime.now().isoformat()
        }
    
    def reset_circuit_breakers(self):
        """Reset all circuit breakers (for testing/manual recovery)"""
        self.repliers_breaker.reset()
        self.exa_breaker.reset()
        logger.info("All circuit breakers manually reset")
    
    def clear_caches(self):
        """Clear all caches"""
        warm_cleared = self.cache.clear()
        historical_cleared = self.historical_cache.clear()
        logger.info(f"Caches cleared: {warm_cleared} warm, {historical_cleared} historical")


# Global instance
resilient_property_service = ResilientPropertyService()


def circuit_breaker_decorator(breaker: CircuitBreaker):
    """
    Decorator to apply circuit breaker to any function
    
    Usage:
        @circuit_breaker_decorator(my_breaker)
        def my_api_call():
            ...
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs):
            return breaker.call(func, *args, **kwargs)
        return wrapper
    return decorator
